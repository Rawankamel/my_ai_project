{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999fc757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI Developer now!\n"
     ]
    }
   ],
   "source": [
    "print(\"I am an AI Developer now!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d25959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Version: 3.0.0\n",
      "Numpy Version: 2.4.2\n",
      "All libraries are ready for AI! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Pandas Version:\", pd.__version__)\n",
    "print(\"Numpy Version:\", np.__version__)\n",
    "print(\"All libraries are ready for AI! ðŸš€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c65ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It works!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model=\"glm-4.7:cloud\")\n",
    "print(\"It works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2b789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø´ØºÙ„\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Ø¨Ù†Ø¹Ø±Ù Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
    "model = ChatOllama(model=\"glm-4.7:cloud\", temperature=0)\n",
    "print(\"âœ… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø´ØºÙ„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9c08101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ø§Ù„Ù†ØªÙŠØ¬Ø© ---\n",
      "Fixed login bug and updated database schema to support new user roles.\n"
     ]
    }
   ],
   "source": [
    "# Ø¨Ù†Ø¹Ù…Ù„ Ù‚Ø§Ù„Ø¨ ÙŠØ®Ù„ÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙ„Ø®Øµ Ø³Ø¬Ù„Ø§Øª Git ÙÙŠ Ø³Ø·Ø± ÙˆØ§Ø­Ø¯\n",
    "template = \"Summarize the following git commit log into a one-line release note: {log}\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Ù…Ø«Ø§Ù„ Ù„Ø³Ø¬Ù„ (Log) Ø¹Ø§ÙˆØ²ÙŠÙ† Ù†Ù„Ø®ØµÙ‡\n",
    "sample_log = \"Fixed a bug in the login system and updated the database schema to support new user roles.\"\n",
    "\n",
    "# Ø¯Ù…Ø¬ Ø§Ù„Ø³Ø¬Ù„ Ù…Ø¹ Ø§Ù„Ù‚Ø§Ù„Ø¨\n",
    "final_input = prompt.format(log=sample_log)\n",
    "\n",
    "# Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø£Ù…Ø± Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
    "response = model.invoke(final_input)\n",
    "\n",
    "print(\"--- Ø§Ù„Ù†ØªÙŠØ¬Ø© ---\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d75cede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template is ready.\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ¹Ù„Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ®ØªØµØ± Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù€ Git\n",
    "template = \"Summarize the following git commit log into a one-line release note: {log}\"\n",
    "\n",
    "# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø§Ø¯ÙŠ Ù„Ù‚Ø§Ù„Ø¨ Ø±Ø³Ù…ÙŠ Ù…Ù† LangChain\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "print(\"Template is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0169c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Log: added a new feature to the login page and fixed some minor bugs in the dashboard\n",
      "--------------------\n",
      "Summarized Note: Added new login feature and fixed minor dashboard bugs.\n"
     ]
    }
   ],
   "source": [
    "# Ù…Ø«Ø§Ù„ Ù„ÙƒÙ„Ø§Ù… Ø·ÙˆÙŠÙ„ (Log) Ø¹Ø§ÙˆØ²ÙŠÙ† Ù†Ù„Ø®ØµÙ‡\n",
    "log_input = \"added a new feature to the login page and fixed some minor bugs in the dashboard\"\n",
    "\n",
    "# Ø¯Ù…Ø¬ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¬ÙˆÙ‡ Ø§Ù„Ù‚Ø§Ù„Ø¨\n",
    "formatted_prompt = prompt.format(log=log_input)\n",
    "\n",
    "# Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø£Ù…Ø± Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ø±Ø¯\n",
    "response = model.invoke(formatted_prompt)\n",
    "\n",
    "# Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©\n",
    "print(\"Original Log:\", log_input)\n",
    "print(\"-\" * 20)\n",
    "print(\"Summarized Note:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c4a6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized Note: Added a new login feature and fixed minor dashboard bugs.\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„Ù„ÙŠ ÙƒØ§Ù† ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©\n",
    "log_input = \"added a new feature to the login page and fixed some minor bugs in the dashboard\"\n",
    "\n",
    "# Ø¯Ù…Ø¬ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¬ÙˆÙ‡ Ø§Ù„Ù‚Ø§Ù„Ø¨\n",
    "formatted_prompt = prompt.format(log=log_input)\n",
    "\n",
    "# Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø£Ù…Ø± Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
    "response = model.invoke(formatted_prompt)\n",
    "\n",
    "print(\"Summarized Note:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24f24042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Result from Chain ---\n",
      "raw response: content='Patched security vulnerabilities and optimized database queries for faster loading.' additional_kwargs={} response_metadata={'model': 'glm-4.7:cloud', 'created_at': '2026-02-13T19:49:55.253177189Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4807680315, 'load_duration': None, 'prompt_eval_count': 31, 'prompt_eval_duration': None, 'eval_count': 602, 'eval_duration': None, 'logprobs': None, 'model_name': 'glm-4.7:cloud', 'model_provider': 'ollama'} id='lc_run--019c588d-700f-7542-946a-2878fb7c959f-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 31, 'output_tokens': 602, 'total_tokens': 633}\n",
      "Patched security vulnerabilities and optimized database queries for faster loading.\n"
     ]
    }
   ],
   "source": [
    "# 1. Ø¨Ù†Ø±Ø¨Ø· Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø¨Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ \"Ø³Ù„Ø³Ù„Ø©\" ÙˆØ§Ø­Ø¯Ø©\n",
    "# Ø¯ÙŠ Ø§Ù„Ù„ÙŠ Ø¨Ù†Ø³Ù…ÙŠÙ‡Ø§ Ø§Ù„Ù€ Chain\n",
    "chain = prompt | model\n",
    "\n",
    "# 2. Ø¨Ù†Ø¬Ù‡Ø² Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª (Ø§Ù„Ù€ Input)\n",
    "log_entry = \"fixed several security vulnerabilities and optimized database queries for faster loading\"\n",
    "\n",
    "# 3. Ø¨Ù†Ø´ØºÙ„ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ÙƒÙ„Ù‡Ø§ Ø¨Ù„Ù…Ø³Ø© ÙˆØ§Ø­Ø¯Ø©\n",
    "# Ù„Ø§Ø­Ø¸ÙŠ Ù‡Ù†Ø§ Ø¨Ù†Ø¨Ø¹Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙƒÙ€ Dictionary { \"Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±\": Ø§Ù„Ù‚ÙŠÙ…Ø© }\n",
    "response = chain.invoke({\"log\": log_entry})\n",
    "\n",
    "# 4. Ø¨Ù†Ø·Ø¨Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©\n",
    "print(\"--- Result from Chain ---\")\n",
    "print(f\"raw response: {response}\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ededfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Menu Description ---\n",
      "Here are a few options, ranging from classic to rustic:\n",
      "\n",
      "**Option 1 (Classic & Savory)**\n",
      "\"A timeless classic featuring a golden, hand-tossed crust topped with zesty tomato sauce and a bubbly blanket of premium mozzarella. Finished with a generous sprinkle of aromatic herbs and fresh basil for a simple, savory slice of perfection.\"\n",
      "\n",
      "**Option 2 (Short & Punchy)**\n",
      "\"Crispy, golden, and irresistibly gooey. Our signature crust is loaded with melted mozzarella and a zesty tomato base, finished with a fragrant dusting of Italian herbs.\"\n",
      "\n",
      "**Option 3 (Rustic)**\n",
      "\"Simple yet sublime. We bake our dough to a perfect crisp, layering it with slow-simmered tomato sauce and a rich blend of melting cheeses, garnished with a fresh medley of garden herbs.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1. Ø³Ù…ÙŠÙ†Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ \"chef_brain\"\n",
    "chef_brain = ChatOllama(model=\"glm-4.7:cloud\", temperature=0.7) # Ø²ÙˆØ¯Ù†Ø§ Ø§Ù„Ù€ temperature Ø¹Ø´Ø§Ù† ÙŠØ¨Ø¯Ø¹ ÙÙŠ Ø§Ù„ÙˆØµÙ\n",
    "\n",
    "# 2. Ø³Ù…ÙŠÙ†Ø§ Ø§Ù„Ù‚Ø§Ù„Ø¨ \"menu_template\"\n",
    "# Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù„ÙŠ Ø¬ÙˆÙ‡ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø³Ù…ÙŠÙ†Ø§Ù‡ {dish_name}\n",
    "menu_template = PromptTemplate.from_template(\n",
    "    \"Write a short, mouth-watering description for a restaurant menu about this dish: {dish_name}\"\n",
    ")\n",
    "\n",
    "# 3. Ø¹Ù…Ù„Ù†Ø§ Ø§Ù„Ø³Ù„Ø³Ù„Ø© ÙˆØ³Ù…ÙŠÙ†Ø§Ù‡Ø§ \"description_chain\"\n",
    "description_chain = menu_template | chef_brain\n",
    "\n",
    "# 4. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø¨ÙƒÙ„Ù…Ø© (Ø¨ÙŠØªØ²Ø§ Ø¨Ø§Ù„Ø¬Ø¨Ù†Ø©)\n",
    "final_result = description_chain.invoke({\"dish_name\": \"Cheese Pizza with herbs\"})\n",
    "\n",
    "print(\"--- Menu Description ---\")\n",
    "print(final_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "137cd19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ø®Ø·Ø© Ø§Ù„Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠØ© ---\n",
      "Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ Ø£ÙŠÙ‡Ø§ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ù…Ø¨Ø¯Ø¹! ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ø¬Ø¯Ø§Ù‹ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ØªØ­Ø¶ÙŠØ± Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø³ Ø§Ù„Ø­ÙŠÙˆÙŠ. Ø¥Ù„ÙŠÙƒ Ø®Ø·Ø© Ø´Ø±Ø­ Ù„Ø¯Ø±Ø³ \"Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ø§Ù„Ø£Ø±Ø¶ÙŠØ©\" Ù…ØµÙ…Ù…Ø© Ù„ØªÙƒÙˆÙ† Ø¨Ø³ÙŠØ·Ø©ØŒ Ù…Ù…ØªØ¹Ø©ØŒ ÙˆØªÙØ§Ø¹Ù„ÙŠØ©ØŒ ÙˆØªØ­Ø§ÙƒÙŠ Ø¹Ù‚ÙˆÙ„ Ø§Ù„Ø·Ù„Ø§Ø¨ ÙˆØªØ´Ø¹Ù„ ÙØ¶ÙˆÙ„Ù‡Ù….\n",
      "\n",
      "***\n",
      "\n",
      "### Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¯Ø±Ø³: \"Ø§Ù„Ù…ØºÙ†Ø§Ø·ÙŠØ³ Ø§Ù„Ø®ÙÙŠ: ÙƒÙŠÙ ØªÙ…Ø³ÙƒÙ†Ø§ Ø§Ù„Ø£Ø±Ø¶ØŸ\"\n",
      "\n",
      "**ðŸŒŸ Ø§Ù„Ù‡Ø¯Ù:** Ø£Ù† ÙŠÙÙ‡Ù… Ø§Ù„Ø·Ù„Ø§Ø¨ Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ø§Ù„Ø£Ø±Ø¶ÙŠØ© ÙƒÙ‚ÙˆØ© Ø·Ø¨ÙŠØ¹ÙŠØ© ØªØ¬Ø°Ø¨ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ Ù†Ø­Ùˆ Ù…Ø±ÙƒØ² Ø§Ù„Ø£Ø±Ø¶.\n",
      "\n",
      "---\n",
      "\n",
      "#### 1. Ù…Ù‚Ø¯Ù…Ø© ØªØ¬Ø°Ø¨ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ (Ø§Ù„Ø®Ø·Ø§Ù)\n",
      "**Ù†Ø´Ø§Ø· Ø³Ø±ÙŠØ¹: \"Ù‚ÙØ²Ø© Ø§Ù„Ù‚Ø²Ù…\"**\n",
      "\n",
      "*   **Ù…Ø§ ØªÙ‚ÙˆÙ„Ù‡ Ù„Ù„Ø·Ù„Ø§Ø¨:** \"Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨ÙƒÙ… Ø£ÙŠÙ‡Ø§ Ø§Ù„ÙØ¶Ø§Ø¦ÙŠÙˆÙ† Ø§Ù„ØµØºØ§Ø±! Ù‚Ø¨Ù„ Ø£Ù† Ù†Ø¨Ø¯Ø£ØŒ Ø£Ø±ÙŠØ¯ Ù…Ù†ÙƒÙ… Ø¬Ù…ÙŠØ¹Ø§Ù‹ Ø§Ù„ÙˆÙ‚ÙˆÙ ÙˆØ§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‚ÙØ²Ø© ØµØºÙŠØ±Ø© ÙÙŠ Ø§Ù„Ù‡ÙˆØ§Ø¡.. ÙˆØ§Ø­Ø¯.. Ø§Ø«Ù†Ø§Ù†.. Ø«Ù„Ø§Ø«Ø©.. Ø§Ù†Ø·Ù„Ù‚ÙˆØ§!\"\n",
      "*   **Ø¨Ù…Ø§Ø°Ø§ ÙŠÙ„Ø§Ø­Ø¸ÙˆÙ†ØŸ** Ø³ÙŠØ¹ÙˆØ¯ Ø§Ù„Ø¬Ù…ÙŠØ¹ Ø¥Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶.\n",
      "*   **Ø§Ù„ØªØ¹Ù„ÙŠÙ‚:** \"Ø±Ø§Ø¦Ø¹! Ù„Ù‚Ø¯ Ø¹Ø¯ØªÙ… Ø¬Ù…ÙŠØ¹Ø§Ù‹ Ø¥Ù„Ù‰ seatsÙƒÙ… (Ù…Ù‚Ø§Ø¹Ø¯ÙƒÙ…). Ø§Ù„Ø³Ø¤Ø§Ù„ Ù‡Ùˆ: Ù„Ù…Ø§Ø°Ø§ Ù„Ù… ØªØ·ÙŠØ± ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡ØŸ Ù„Ù…Ø§Ø°Ø§ Ù„Ù… ØªØ¨Ù‚ÙŽ Ø¹Ø§Ù„Ù‚Ø§Ù‹ ÙÙŠ Ø§Ù„Ø³Ù‚ÙØŸ Ù‡Ù†Ø§Ùƒ Ù‚ÙˆØ© Ø®ÙÙŠØ© Ù‚ÙˆÙŠØ© Ø¬Ø¯Ø§Ù‹ ØªÙ…Ø³Ùƒ Ø¨Ù†Ø§ ÙˆØªØ´Ø¯Ù†Ø§ Ø¨Ø§Ø³ØªÙ…Ø±Ø§Ø± Ù†Ø­Ùˆ Ø§Ù„Ø£Ø³ÙÙ„.. Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙˆØ© Ù†Ø³Ù…ÙŠÙ‡Ø§ **(Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ø§Ù„Ø£Ø±Ø¶ÙŠØ©)**. ØªØ®ÙŠÙ„Ù‡Ø§ ÙˆÙƒØ£Ù† Ø§Ù„Ø£Ø±Ø¶ ØªÙ…ØªÙ„Ùƒ Ù…ØºÙ†Ø§Ø·ÙŠØ³Ø§Ù‹ Ø¹Ù…Ù„Ø§Ù‚Ø§Ù‹ ÙŠØ­Ø¨Ù†Ø§ Ø¬Ø¯Ø§Ù‹ ÙˆÙ„Ø§ ÙŠØ±ÙŠØ¯Ù†Ø§ Ø£Ù† Ù†ØºØ§Ø¯Ø±Ù‡!\"\n",
      "\n",
      "---\n",
      "\n",
      "#### 2. Ù…Ø¹Ù„ÙˆÙ…Ø© ØºØ±ÙŠØ¨Ø© ÙˆÙ…Ø¯Ù‡Ø´Ø© (Ø¹Ù†ØµØ± Ø§Ù„Ù…ÙØ§Ø¬Ø£Ø©)\n",
      "**Ø­Ù‚ÙŠÙ‚Ø© ÙƒÙˆÙƒØ¨ÙŠØ© Ù…Ø°Ù‡Ù„Ø©**\n",
      "\n",
      "*   **Ù…Ø§ ØªÙ‚ÙˆÙ„Ù‡ Ù„Ù„Ø·Ù„Ø§Ø¨:** \"Ù‡Ù„ ØªØ¹Ù„Ù…ÙˆÙ† Ø£Ù† Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ù„ÙŠØ³Øª Ø«Ø§Ø¨ØªØ© ÙÙŠ ÙƒÙ„ Ù…ÙƒØ§Ù†ØŸ ØªØ®ÙŠÙ„ÙˆØ§ Ù„Ùˆ Ø³Ø§ÙØ±Ù†Ø§ Ø¥Ù„Ù‰ ÙƒÙˆÙƒØ¨ Ø¢Ø®Ø±.\"\n",
      "*   **Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©:** \"Ù„Ùˆ ÙˆÙ‚ÙÙ†Ø§ Ø¹Ù„Ù‰ Ø³Ø·Ø­ Ø§Ù„Ù‚Ù…Ø±ØŒ Ù„ÙƒØ§Ù†Øª Ø¬Ø§Ø°Ø¨ÙŠØªÙ‡ Ø£Ø¶Ø¹Ù Ø¨ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø£Ø±Ø¶. Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†ÙƒÙ… ØªØ³ØªØ·ÙŠØ¹ÙˆÙ† Ø§Ù„Ù‚ÙØ² Ø¹Ø§Ù„ÙŠØ§Ù‹ Ø¬Ø¯Ø§Ù‹ ÙÙŠ Ø§Ù„Ø³Ù…Ø§Ø¡.. Ø³ØªÙ‚ÙØ²ÙˆÙ† ÙƒØ£Ù†ÙƒÙ… Ø£Ø¨Ø·Ø§Ù„ Ø§Ù„Ø®Ø§Ø±Ù‚ÙŠÙ† ÙÙŠ Ø§Ù„Ø£ÙÙ„Ø§Ù…! ÙˆØ¨Ø§Ù„Ø¹ÙƒØ³ØŒ Ù„Ùˆ Ø°Ù‡Ø¨ØªÙ… Ø¥Ù„Ù‰ ÙƒÙˆÙƒØ¨ Ø§Ù„Ù…Ø´ØªØ±ÙŠØŒ Ù„ÙƒØ§Ù† ÙˆØ²Ù†ÙƒÙ… Ø«Ù‚ÙŠÙ„Ø§Ù‹ Ù„Ø¯Ø±Ø¬Ø© Ø£Ù†ÙƒÙ… Ù„Ù† ØªØ³ØªØ·ÙŠØ¹ÙˆØ§ Ø­ØªÙ‰ Ø§Ù„Ù…Ø´ÙŠ Ø£Ùˆ Ø±ÙØ¹ Ù‚Ø¯Ù…ÙƒÙ… Ø¹Ù† Ø§Ù„Ø£Ø±Ø¶!\"\n",
      "*   **Ø§Ù„Ø®Ù„Ø§ØµØ©:** \"Ù†Ø­Ù† Ù…Ø­Ø¸ÙˆØ¸ÙˆÙ† Ø¨Ø¬Ø§Ø°Ø¨ÙŠØ© Ø§Ù„Ø£Ø±Ø¶Ø› ÙÙ‡ÙŠ Ù„ÙŠØ³Øª Ù‚ÙˆÙŠØ© Ø¬Ø¯Ø§Ù‹ Ù„ØªØ³Ø­Ù‚Ù†Ø§ØŒ ÙˆÙ„ÙŠØ³Øª Ø¶Ø¹ÙŠÙØ© Ø¬Ø¯Ø§Ù‹ Ù„ØªØ¬Ø¹Ù„Ù†Ø§ Ù†Ø·ÙŠØ±ØŒ Ø¨Ù„ Ù‡ÙŠ Ù…Ø«Ø§Ù„ÙŠØ© ØªÙ…Ø§Ù…Ø§Ù‹ Ù„Ø­ÙŠØ§ØªÙ†Ø§.\"\n",
      "\n",
      "---\n",
      "\n",
      "#### 3. Ø³Ø¤Ø§Ù„ ØªÙØ§Ø¹Ù„ÙŠ Ù„Ù„Ù…Ù†Ø§Ù‚Ø´Ø© (Ø¥Ø´Ø¹Ø§Ù„ Ø§Ù„Ø¹Ù‚ÙˆÙ„)\n",
      "**Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ \"Ù…Ø§Ø°Ø§ Ù„ÙˆØŸ\"**\n",
      "\n",
      "*   **Ø§Ù„Ø³Ø¤Ø§Ù„:** \"Ø£Ø­Ø¨ Ø£Ù† Ø£Ø³Ù…Ø¹ Ø¢Ø±Ø§Ø¡ÙƒÙ…: ØªØ®ÙŠÙ„ÙˆØ§ Ù…Ø¹ÙŠ Ø£Ù† Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ø§Ù„Ø£Ø±Ø¶ÙŠØ© ØªÙˆÙ‚ÙØª Ø¹Ù† Ø§Ù„Ø¹Ù…Ù„ Ù„Ù…Ø¯Ø© **5 Ø¯Ù‚Ø§Ø¦Ù‚ ÙÙ‚Ø·** ÙÙŠ ÙØµÙ„Ù†Ø§ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ.. Ù…Ø§ Ù‡Ùˆ Ø£ÙˆÙ„ Ø´ÙŠØ¡ Ø³ÙŠØ­Ø¯Ø«ØŸ ÙˆÙƒÙŠÙ Ø³ØªØªØµØ±ÙÙˆÙ†ØŸ\"\n",
      "*   **ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù†Ù‚Ø§Ø´ (Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ù…ØªØ¹Ø©):**\n",
      "    *   Ù‡Ù„ Ø³ØªØ¨Ù‚Ù‰ Ø§Ù„ÙƒØªØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø§ÙˆÙ„Ø§ØªØŸ\n",
      "    *   Ù‡Ù„ Ø³ÙŠØ¨Ù‚Ù‰ Ø§Ù„Ù…Ø§Ø¡ ÙÙŠ Ø§Ù„ÙƒØ£Ø³ØŸ\n",
      "    *   Ù‡Ù„ Ø³Ù†Ø³ØªØ·ÙŠØ¹ Ø§Ù„Ù…Ø´ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¶ØŸ\n",
      "*   **Ø§Ù„Ù‡Ø¯Ù Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„:** ØªÙˆØ¶ÙŠØ­ Ø£Ù† Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ù‡ÙŠ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„Ø© Ø¹Ù† Ø«Ø¨Ø§Øª Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ ÙˆØ³Ù‚ÙˆØ·Ù‡Ø§ØŒ ÙˆØ¨Ø¯ÙˆÙ†Ù‡Ø§ Ø³ØªØ¹Ù… Ø§Ù„ÙÙˆØ¶Ù‰ ÙˆØ³ÙŠØ·ÙÙˆ ÙƒÙ„ Ø´ÙŠØ¡ ÙÙŠ Ø§Ù„Ù‡ÙˆØ§Ø¡!\n",
      "\n",
      "---\n",
      "\n",
      "**ðŸ’¡ Ù†ØµÙŠØ­Ø© Ù„Ù„Ù…Ø¹Ù„Ù…:**\n",
      "Ø§Ø®ØªÙ… Ø§Ù„Ø¯Ø±Ø³ Ø¨Ø§Ø¨ØªØ³Ø§Ù…Ø© ÙˆÙ‚Ù„ Ù„Ù‡Ù…: \"Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ù‡ÙŠ Ø§Ù„ØªÙŠ ØªØ¬Ø¹Ù„Ù†Ø§ Ù†Ø´Ø¹Ø± Ø¨Ø§Ù„Ø£Ù…Ø§Ù† ØªØ­Øª Ø£Ù‚Ø¯Ø§Ù…Ù†Ø§ØŒ Ù„Ø°Ø§ Ø¯Ø¹ÙˆÙ†Ø§ Ù†Ø´ÙƒØ± Ø§Ù„Ø£Ø±Ø¶ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ 'Ø§Ù„Ø¹Ù†Ø§Ù‚ Ø§Ù„Ù…Ø³ØªÙ…Ø±'!\"\n",
      "\n",
      "Ø£ØªÙ…Ù†Ù‰ Ù„Ùƒ Ø¯Ø±Ø³Ø§Ù‹ Ù…Ù„ÙŠØ¦Ø§Ù‹ Ø¨Ø§Ù„Ù…Ø±Ø­ ÙˆØ§Ù„ÙØ§Ø¦Ø¯Ø©\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ³Ù…ÙŠÙ†Ø§Ù‡ \"Ø§Ù„Ù…Ø¹Ù„Ù…_Ø§Ù„Ø°ÙƒÙŠ\"\n",
    "# Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ temperature=0.5 Ø¹Ø´Ø§Ù† ÙŠØ¯ÙŠÙ†Ø§ Ø£ÙÙƒØ§Ø± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© Ø´ÙˆÙŠØ© ÙÙŠ Ø§Ù„Ø´Ø±Ø­\n",
    "Ø§Ù„Ù…Ø¹Ù„Ù…_Ø§Ù„Ø°ÙƒÙŠ = ChatOllama(model=\"glm-4.7:cloud\", temperature=0.5)\n",
    "\n",
    "# 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù‚Ø§Ù„Ø¨ ÙˆØ³Ù…ÙŠÙ†Ø§Ù‡ \"Ù‚Ø§Ù„Ø¨_Ø§Ù„Ø¯Ø±Ø³\"\n",
    "# Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù„ÙŠ Ø¬ÙˆÙ‡ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø³Ù…ÙŠÙ†Ø§Ù‡ {Ø§Ø³Ù…_Ø§Ù„Ø¯Ø±Ø³}\n",
    "Ù†Øµ_Ø§Ù„Ù‚Ø§Ù„Ø¨ = \"\"\"\n",
    "Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ø®Ø¨ÙŠØ± ÙˆÙ…Ø¨Ø¯Ø¹. \n",
    "Ø§ÙƒØªØ¨ Ù„ÙŠ Ø®Ø·Ø© Ø´Ø±Ø­ Ù…Ø¨Ø³Ø·Ø© ÙˆÙ…Ù…ØªØ¹Ø© Ù„Ø¯Ø±Ø³ Ø¹Ù†: {Ø§Ø³Ù…_Ø§Ù„Ø¯Ø±Ø³}\n",
    "ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ¶Ù…Ù† Ø§Ù„Ø®Ø·Ø©:\n",
    "1. Ù…Ù‚Ø¯Ù…Ø© ØªØ¬Ø°Ø¨ Ø§Ù†ØªØ¨Ø§Ù‡ Ø§Ù„Ø·Ù„Ø§Ø¨.\n",
    "2. Ù…Ø¹Ù„ÙˆÙ…Ø© ØºØ±ÙŠØ¨Ø© Ø£Ùˆ Ù…Ø¯Ù‡Ø´Ø© Ø¹Ù† Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹.\n",
    "3. Ø³Ø¤Ø§Ù„ ØªÙØ§Ø¹Ù„ÙŠ Ù„Ù„Ù…Ù†Ø§Ù‚Ø´Ø©.\n",
    "Ø§ÙƒØªØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø´Ø¬Ø¹.\n",
    "\"\"\"\n",
    "\n",
    "Ù‚Ø§Ù„Ø¨_Ø§Ù„Ø¯Ø±Ø³ = PromptTemplate.from_template(Ù†Øµ_Ø§Ù„Ù‚Ø§Ù„Ø¨)\n",
    "\n",
    "# 3. Ø¹Ù…Ù„ Ø§Ù„Ø³Ù„Ø³Ù„Ø© (The Chain)\n",
    "Ø³Ù„Ø³Ù„Ø©_Ø§Ù„ØªØ¹Ù„ÙŠÙ… = Ù‚Ø§Ù„Ø¨_Ø§Ù„Ø¯Ø±Ø³ | Ø§Ù„Ù…Ø¹Ù„Ù…_Ø§Ù„Ø°ÙƒÙŠ\n",
    "\n",
    "# 4. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³Ù„Ø³Ù„Ø©\n",
    "# Ù‡Ù†Ø¬Ø±Ø¨ Ù†Ø·Ù„Ø¨ Ù…Ù†Ù‡ ÙŠØ´Ø±Ø­ \"Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ø§Ù„Ø£Ø±Ø¶ÙŠØ©\"\n",
    "Ø§Ù„Ù†ØªÙŠØ¬Ø© = Ø³Ù„Ø³Ù„Ø©_Ø§Ù„ØªØ¹Ù„ÙŠÙ….invoke({\"Ø§Ø³Ù…_Ø§Ù„Ø¯Ø±Ø³\": \"Ø§Ù„Ø¬Ø§Ø°Ø¨ÙŠØ© Ø§Ù„Ø£Ø±Ø¶ÙŠØ©\"})\n",
    "\n",
    "print(\"--- Ø®Ø·Ø© Ø§Ù„Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠØ© ---\")\n",
    "print(Ø§Ù„Ù†ØªÙŠØ¬Ø©.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acb4b1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¥Ù„ÙŠÙƒÙ Ø®ÙŠØ§Ø±Ø§Øª Ù‚ØµÙŠØ±Ø© ÙˆÙ…Ø¨Ù‡Ø¬Ø©:\n",
      "\n",
      "**Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙˆÙ„ (Ø¹Ø§Ø·ÙÙŠ ÙˆØ¯Ø§ÙØ¦):**\n",
      "\"ØµØ¨Ø§Ø­ Ø§Ù„Ù†ÙˆØ± ÙˆØ§Ù„Ø³Ø±ÙˆØ± ÙŠØ§ Ù…Ø§Ù…Ø§! â˜€ï¸\n",
      "Ø£Ø±Ø¬Ùˆ Ø£Ù† ÙŠÙ…Ù„Ø£ ÙŠÙˆÙ…Ùƒ Ø§Ù„ÙØ±Ø­Ø© ÙˆØ§Ù„Ù‡Ø¯ÙˆØ¡ØŒ Ù„Ø£Ù†Ùƒ ØªØ³ØªØ­Ù‚ÙŠÙ† ÙƒÙ„ Ø®ÙŠØ±. Ø£Ø­Ø¨ÙƒÙ! â¤ï¸\"\n",
      "\n",
      "**Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø«Ø§Ù†ÙŠ (Ø®ÙÙŠÙ ÙˆÙ…Ø±Ø­):**\n",
      "\"ØµØ¨Ø§Ø­Ùƒ ÙˆØ±Ø¯ ÙŠØ§ Ø£ØºÙ„Ù‰ Ù…Ø§Ù…Ø§! ðŸŒ¹\n",
      "Ø£ØªÙ…Ù†Ù‰ Ù„ÙƒÙ ÙŠÙˆÙ…Ù‹Ø§ Ø³Ø¹ÙŠØ¯Ù‹Ø§ ÙˆÙ…Ù„ÙŠØ¦Ù‹Ø§ Ø¨Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©ØŒ ÙƒÙ„ Ø¹Ø§Ù… ÙˆØ£Ù†ØªÙ Ø¨Ø®ÙŠØ±!\"\n",
      "\n",
      "**Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø«Ø§Ù„Ø« (Ù…Ø®ØªØµØ± Ø¬Ø¯Ø§Ù‹):**\n",
      "\"ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ± ÙŠØ§ Ù‚Ù„Ø¨ÙŠ â¤ï¸\n",
      "ÙŠØ§ Ø±Ø¨ ÙŠÙƒÙˆÙ† ØµØ¨Ø§Ø­Ùƒ Ø£Ø¬Ù…Ù„ Ù…Ù† Ø§Ù„Ø¶Ø­ÙƒØ© Ø¹Ù„Ù‰ ÙˆØ´Ùƒ! ÙŠÙˆÙ… Ø³Ø¹ÙŠØ¯ ÙŠØ§ Ù…Ø§Ù…Ø§.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1. Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù„ÙŠ Ø¨ÙŠÙÙƒØ±)\n",
    "model = ChatOllama(model=\"glm-4.7:cloud\")\n",
    "\n",
    "# 2. Ø§Ù„Ù‚Ø§Ù„Ø¨ (Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø«Ø§Ø¨ØªØ© Ø§Ù„Ù„ÙŠ Ø¨Ù†ØºÙŠØ± ÙÙŠÙ‡Ø§ Ø§Ù„Ø§Ø³Ù… Ø¨Ø³)\n",
    "# ÙƒÙ„Ù…Ø© {name} Ù‡ÙŠ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„ÙØ§Ø¶ÙŠ Ø§Ù„Ù„ÙŠ Ù‡Ù†Ø­Ø· ÙÙŠÙ‡ Ø§Ù„Ø§Ø³Ù…\n",
    "template = \"Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„Ø© ØµØ¨Ø§Ø­ÙŠØ© Ù‚ØµÙŠØ±Ø© ÙˆÙ…Ø¨Ù‡Ø¬Ø© Ù„Ø´Ø®Øµ Ø§Ø³Ù…Ù‡ {name}\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 3. Ø§Ù„Ø³Ù„Ø³Ù„Ø© (Ø§Ù„Ø±Ø¨Ø· Ø¨ÙŠÙ†Ù‡Ù…)\n",
    "# Ù‡Ù†Ø§ Ø¨Ù†Ù‚ÙˆÙ„: Ø®Ø¯ Ø§Ù„Ø§Ø³Ù… -> Ø­Ø·Ù‡ ÙÙŠ Ø§Ù„Ù‚Ø§Ù„Ø¨ -> Ø§Ø¨Ø¹ØªÙ‡ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„\n",
    "chain = prompt | model\n",
    "\n",
    "# 4. Ø§Ù„ØªØ´ØºÙŠÙ„ (Ø¨Ù†Ø¯ÙŠÙ„Ù‡ Ø§Ù„Ø§Ø³Ù… Ø¨Ø³)\n",
    "result = chain.invoke({\"name\":\"Ù…Ø§Ù…Ø§\"})\n",
    "\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
